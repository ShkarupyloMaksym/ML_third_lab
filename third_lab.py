# -*- coding: utf-8 -*-
"""third_lab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w5kDbR_LKIp0sPAJTJfEbtveqbgP6zT_

# Download with pip
"""

# !pip install --upgrade gdown

"""# Imports"""

import pandas as pd
import matplotlib.pyplot as plt
import os
import gdown
import re
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import classification_report, confusion_matrix
import sklearn.metrics as skm

import graphviz
import seaborn as sns

"""# Constants"""

file_url = 'https://drive.google.com/file/d/1IVGHhWUq8ee5YNf0fdy1Rk1C3HXQgxb4/view?usp=drive_link'
data_file_name = 'data.csv'

"""# Some functions"""

def get_alphabet_position(letter):
    letter = letter.lower()
    alphabet = 'абвгґдеєжзиіїйклмнопрстуфхцчшщьюя'
    return alphabet.index(letter) + 1

def convert_drive_link(original_link):
  if "https://drive.google.com/uc?id=" in original_link:
    return original_link
  original_link = original_link.replace('?usp=sharing', '').replace('?usp=drive_link', '')
  pattern = r"https://drive\.google\.com/file/d/([a-zA-Z0-9_-]+)/view"

  matcher = re.match(pattern, original_link)

  if matcher:
    file_id = matcher.group(1)
    converted_link = f"https://drive.google.com/uc?id={file_id}"
    return converted_link
  else:
    raise Exception(f"Not realized Google Drive link format.\nGiven link is {original_link}")
    return None


def install_from_google_drive(link, name, path=None, force_download = False):
  full_path = name
  if path is not None:
    full_path = os.path.join(path, full_path)
  if not force_download:
    if os.path.exists(full_path):
      print('The data already exists')
      return

  print('Start downloading')
  gdown.download(convert_drive_link(link), full_path, quiet=False)
  print('\nDownloading have ended')

"""# Download data"""

install_from_google_drive(file_url, data_file_name)

"""# Task

## Constants
"""



"""# 1. Відкрити та зчитати наданий файл з даними."""

df = pd.read_csv(data_file_name, sep=';')

"""# 2. Визначити та вивести кількість записів та кількість полів у завантаженому наборі даних."""

shape = df.shape
print(f'Кількість записів: {shape[0]}\nКільість полів: {shape[1]}')

"""# 3. Вивести перші 10 записів набору даних."""

df.head(10)

"""# 4. Розділити набір даних на навчальну (тренувальну) та тестову вибірки."""

df_train, df_test = train_test_split(df, train_size=0.7, random_state=42)

print('Розмір даних для тренування')
shape = df_train.shape
print(f'Кількість записів: {shape[0]}\nКільість полів: {shape[1]}')
print('Розмір даних для тестування')
shape = df_test.shape
print(f'Кількість записів: {shape[0]}\nКільість полів: {shape[1]}')

"""# 5. Використовуючи відповідні функції бібліотеки scikit-learn, збудувати класифікаційну модель дерева прийняття рішень глибини 5 та навчити її на тренувальній вибірці, вважаючи, що в наданому наборі даних цільова характеристика визначається останнім стовпчиком, а всі інші виступають в ролі вихідних аргументів."""

X, y = df_train.iloc[:, :-1], df_train.iloc[:, -1]
x_test, y_test = df_test.iloc[:, :-1], df_test.iloc[:, -1]

tree_clf_g = DecisionTreeClassifier(max_depth=5, criterion='gini')
tree_clf_g.fit(X, y)

tree_clf_e = DecisionTreeClassifier(max_depth=5, criterion='entropy')
tree_clf_e.fit(X, y)

"""# 6. Представити графічно побудоване дерево за допомогою бібліотеки graphviz."""

img = export_graphviz(
  tree_clf_g,
  feature_names=X.columns,
  class_names=list(map(str, y.unique())),
  rounded=True,
  filled=True
)
graph = graphviz.Source(img)
graph

img = export_graphviz(
  tree_clf_e,
  feature_names=X.columns,
  class_names=list(map(str, y.unique())),
  rounded=True,
  filled=True
)
graph = graphviz.Source(img)
graph

"""# 7. Обчислити класифікаційні метрики збудованої моделі для тренувальної та тестової вибірки. Представити результати роботи моделі на тестовій вибірці графічно. Порівняти результати, отриманні при застосуванні різних критеріїв розщеплення: інформаційний приріст на основі ентропії чи неоднорідності Джині."""

def show_prediction_results_deployed(model, x_test, y_test):
  y_predict = model.predict(x_test)
  data = pd.DataFrame(classification_report(y_test, y_predict, output_dict=True, )).T
  data = data.applymap(lambda x: round(x,4))

  # display(data)
  sns.heatmap(confusion_matrix(y_test, y_predict), annot = True, fmt='.0f')

def get_model_metrics_sklearn(true_data, predicted):
  metrics = {'Accuracy': skm.accuracy_score,
             'Precision': lambda t, p: skm.precision_score(t, p, average='weighted'),
             'Recall': lambda t, p: skm.recall_score(t, p, average='weighted'),
             'F-Score': lambda t, p: skm.f1_score(t, p, average='weighted'),
             'Matthews Correlation Coefficient': skm.matthews_corrcoef,
             'Balanced Accuracy': skm.balanced_accuracy_score
             }
  for i in metrics:
      metrics[i] = [metrics[i](true_data, predicted)]
  return pd.DataFrame(metrics)

"""Gini"""

get_model_metrics_sklearn(y, tree_clf_g.predict(X))

res_metrics_g = get_model_metrics_sklearn(y_test, tree_clf_g.predict(x_test))
res_metrics_g

"""Entropy"""

get_model_metrics_sklearn(y, tree_clf_e.predict(X))

res_metrics_e = get_model_metrics_sklearn(y_test, tree_clf_e.predict(x_test))
res_metrics_e

ys = []
for metrics in res_metrics_g.columns:
  ys.append(res_metrics_g.loc[0, metrics])

for i, y in enumerate(ys):
  plt.plot([0, 1], [y]*2, label=res_metrics_g.columns[i])

chosen = [0, 2]
ys = np.sort(ys)
ys = ys[chosen]

plt.title(f'Ploted metrics for test data gini')
plt.xticks([])
plt.yticks([0] + list(ys) + [1])
plt.ylabel('value')
plt.legend()
plt.show()

ys = []
for metrics in res_metrics_e.columns:
  ys.append(res_metrics_e.loc[0, metrics])

for i, y in enumerate(ys):
  plt.plot([0, 1], [y]*2, label=res_metrics_e.columns[i])

chosen = [0, 2]
ys = np.sort(ys)
ys = ys[chosen]

plt.title(f'Ploted metrics for test data entropy')
plt.xticks([])
plt.yticks([0] + list(ys) + [1])
plt.ylabel('value')
plt.legend()
plt.show()

for metrics in res_metrics_g.columns:
  plt.plot([0, 1], [res_metrics_g.loc[0, metrics]] * 2, label='gini')
  plt.plot([0, 1], [res_metrics_e.loc[0, metrics]] * 2, label='entropy')

  plt.title(f'Ploted metrics for {metrics}')
  plt.xticks([])
  plt.yticks([0, 1])
  plt.ylabel('value')
  plt.legend()
  plt.show()

show_prediction_results_deployed(tree_clf_g, X, y)

show_prediction_results_deployed(tree_clf_g, x_test, y_test)

"""# 8. З’ясувати вплив глибини дерева та мінімальної кількості елементів в листі дерева на результати класифікації. Результати представити графічно."""

X, y = df_train.iloc[:, :-1], df_train.iloc[:, -1]
x_test, y_test = df_test.iloc[:, :-1], df_test.iloc[:, -1]

xs, ys_tst, ys_trn = [], [], []
for i in range(1, 100):
  m = DecisionTreeClassifier(min_samples_leaf=i, random_state=42)
  m.fit(X, y)
  xs.append(i)
  ys_trn.append(skm.accuracy_score(y, m.predict(X)))
  ys_tst.append(skm.accuracy_score(y_test, m.predict(x_test)))

plt.plot(xs, ys_tst, label='test')
plt.plot(xs, ys_trn, label='train')
plt.legend()
plt.title('Bплив мінімальної кількості елементів в листі дерева на результати класифікації.')
plt.show()

xs, ys_tst, ys_trn = [], [], []
for i in range(1, 30):
  m = DecisionTreeClassifier(max_depth=i, random_state=42)
  m.fit(X, y)
  xs.append(i)
  ys_trn.append(skm.accuracy_score(y, m.predict(X)))
  ys_tst.append(skm.accuracy_score(y_test, m.predict(x_test)))

plt.plot(xs, ys_tst, label='test')
plt.plot(xs, ys_trn, label='train')
plt.legend()
plt.title('Bплив максимальної глибини дерева на результати класифікації.')
plt.show()

"""# 9. Навести стовпчикову діаграму важливості атрибутів, які використовувалися для класифікації (див. feature_importances_). Пояснити, яким чином – на Вашу думку – цю важливість можна підрахувати."""

feature_importances = tree_clf_e.feature_importances_

feature_names = X.columns

sorted_idx = feature_importances.argsort()
plt.figure(figsize=(10, 7))
plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align='center')
plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])
plt.xlabel("Величина")
plt.title("Важливість фіч")
plt.show()
